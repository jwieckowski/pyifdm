{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "from pyifdm import methods\n",
    "from pyifdm.methods import ifs\n",
    "from pyifdm import weights as ifs_weights\n",
    "from pyifdm import correlations as corrs\n",
    "from pyifdm.helpers import rank, generate_ifs_matrix\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data\n",
    "\n",
    "To enable multi-criteria evaluation, the decision matrix needs to be defined. It can be determined based on the real data, or random data generated by the method provided in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.405 0.214]\n",
      "  [0.696 0.008]\n",
      "  [0.015 0.626]\n",
      "  [0.428 0.14 ]]\n",
      "\n",
      " [[0.72  0.278]\n",
      "  [0.003 0.248]\n",
      "  [0.203 0.703]\n",
      "  [0.342 0.385]]\n",
      "\n",
      " [[0.202 0.728]\n",
      "  [0.07  0.215]\n",
      "  [0.26  0.364]\n",
      "  [0.378 0.229]]\n",
      "\n",
      " [[0.857 0.078]\n",
      "  [0.136 0.242]\n",
      "  [0.632 0.296]\n",
      "  [0.388 0.265]]\n",
      "\n",
      " [[0.106 0.852]\n",
      "  [0.088 0.897]\n",
      "  [0.734 0.044]\n",
      "  [0.134 0.207]]]\n"
     ]
    }
   ],
   "source": [
    "# real data matrix\n",
    "matrix = np.array([\n",
    "    [[0.4745, 0.5255], [0.4752, 0.5248], [0.2981, 0.7019], [0.4374, 0.5627]],\n",
    "    [[0.5346, 0.4654], [0.5532, 0.4468], [0.6300, 0.3700], [0.5901, 0.4099]],\n",
    "    [[0.4324, 0.5676], [0.4030, 0.5970], [0.4298, 0.5702], [0.4361, 0.5639]],\n",
    "    [[0.5235, 0.4765], [0.4808, 0.5192], [0.5667, 0.4333], [0.2913, 0.7087]],\n",
    "    [[0.4168, 0.5832], [0.4923, 0.5077], [0.4732, 0.5268], [0.4477, 0.5523]]\n",
    "])\n",
    "\n",
    "# randomly generated matrix\n",
    "# 5 alternatives\n",
    "# 4 criteria\n",
    "random_matrix = generate_ifs_matrix(5, 4)\n",
    "print(random_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "\n",
    "Data normalization converts the range of values that they are placed in range between 0 and 1. Below the usage examples of methods implemented in the library is presented. Types parameter are responsible for the direction of the normalization. One columns' values could be more preferred is the values are lower (`-1` - cost), while others could be more preferred if the values are greater (`1` - profit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecer normalization\n",
      "\n",
      " [[[0.888 0.901]\n",
      "  [0.848 0.851]\n",
      "  [0.473 1.   ]\n",
      "  [0.666 0.728]]\n",
      "\n",
      " [[1.    0.798]\n",
      "  [0.728 1.   ]\n",
      "  [1.    0.527]\n",
      "  [0.494 1.   ]]]\n",
      "\n",
      "minmax_normalization\n",
      "\n",
      " [[[0.49  0.51 ]\n",
      "  [0.519 0.481]\n",
      "  [0.    1.   ]\n",
      "  [0.511 0.489]]\n",
      "\n",
      " [[1.    0.   ]\n",
      "  [0.    1.   ]\n",
      "  [1.    0.   ]\n",
      "  [0.    1.   ]]]\n",
      "\n",
      "Supriya normalization\n",
      "\n",
      " [[[0.888 0.112]\n",
      "  [0.859 0.141]\n",
      "  [0.473 0.527]\n",
      "  [0.741 0.259]]\n",
      "\n",
      " [[1.    0.   ]\n",
      "  [1.    0.   ]\n",
      "  [1.    0.   ]\n",
      "  [1.    0.   ]]]\n",
      "\n",
      "Swap normalization\n",
      "\n",
      " [[[0.474 0.525]\n",
      "  [0.525 0.475]\n",
      "  [0.298 0.702]\n",
      "  [0.563 0.437]]\n",
      "\n",
      " [[0.535 0.465]\n",
      "  [0.447 0.553]\n",
      "  [0.63  0.37 ]\n",
      "  [0.41  0.59 ]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalizations = {\n",
    "    'Ecer normalization': ifs.normalization.ecer_normalization,\n",
    "    'minmax_normalization': ifs.normalization.minmax_normalization,\n",
    "    'Supriya normalization': ifs.normalization.supriya_normalization,\n",
    "    'Swap normalization': ifs.normalization.swap_normalization,\n",
    "}\n",
    "\n",
    "types = np.array([1, -1, 1, -1])\n",
    "\n",
    "for name, norm in normalizations.items():\n",
    "    nmatrix = norm(matrix, types)\n",
    "    print(f'{name}\\n\\n {nmatrix[:2]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance measures\n",
    "\n",
    "Distance measures allow to indicate how different are given two fuzzy numbers. Different techniques have been developed to this end. The measures for the IFS implemented in the library and their usage are presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean: 0.22912878474779197\n",
      "Grzegorzewski: 0.24999999999999994\n",
      "Hamming: 0.24999999999999997\n",
      "Luo distance: 0.11249999999999996\n",
      "Normalized Hamming: 0.24999999999999997\n",
      "Normalized Euclidean: 0.22912878474779197\n",
      "Wang Xin 1: 0.23749999999999996\n",
      "Wang Xin 2: 0.22499999999999998\n",
      "Yang Chiclana: 0.24999999999999994\n"
     ]
    }
   ],
   "source": [
    "distances = {\n",
    "    'Euclidean' : ifs.distance.euclidean_distance,\n",
    "    'Grzegorzewski': ifs.distance.grzegorzewski_distance,\n",
    "    'Hamming': ifs.distance.hamming_distance,\n",
    "    'Luo distance': ifs.distance.luo_distance,\n",
    "    'Normalized Hamming': ifs.distance.normalized_hamming_distance,\n",
    "    'Normalized Euclidean': ifs.distance.normalized_euclidean_distance,\n",
    "    'Wang Xin 1': ifs.distance.wang_xin_distance_1,\n",
    "    'Wang Xin 2': ifs.distance.wang_xin_distance_2,\n",
    "    'Yang Chiclana': ifs.distance.yang_chiclana_distance,\n",
    "}\n",
    "\n",
    "x = np.array([0.7, 0.3])\n",
    "y = np.array([0.45, 0.5])\n",
    "\n",
    "for name, distance in distances.items():\n",
    "    if distance.__name__ == 'normalized_euclidean_distance':\n",
    "        d = np.sqrt(1/2 * distance(x, y))\n",
    "    elif distance.__name__ == 'normalized_hamming_distance':\n",
    "        d = 1/2 * distance(x, y)\n",
    "    else:\n",
    "        d = distance(x, y)\n",
    "    print(f'{name}: {d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score functions\n",
    "\n",
    "To create a crisp ranking from the calculations performed in fuzzy environment, the score functions should be used. Different techniques can be applied to achieve this. The implemented methods and the example of their usage are presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chen score 1: 0.65\n",
      "Chen score 2: 0.825\n",
      "Kharal score 1: 0.7000000000000001\n",
      "Kharal score 2: 0.42500000000000004\n",
      "Liu Wang score: 0.84\n",
      "Supriya score: 0.7925000000000001\n",
      "Thakur score: 0.6175000000000002\n",
      "Wan Dong score 1: 0.6625\n",
      "Wan Dong score 2: 0.825\n",
      "Wei score: 0.563320058063622\n",
      "Zhang Xu score 1: 0.8095238095238094\n",
      "Zhang Xu score 2: 0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "score_functions = {\n",
    "    'Chen score 1': ifs.score.chen_score_1,                                                                                          \n",
    "    'Chen score 2': ifs.score.chen_score_2,                                                                                          \n",
    "    'Kharal score 1': ifs.score.kharal_score_1,                                                                                          \n",
    "    'Kharal score 2': ifs.score.kharal_score_2,                                                                                          \n",
    "    'Liu Wang score': ifs.score.liu_wang_score,                                                                                          \n",
    "    'Supriya score': ifs.score.supriya_score,                                                                                          \n",
    "    'Thakur score': ifs.score.thakur_score,                                                                                          \n",
    "    'Wan Dong score 1': ifs.score.wan_dong_score_1,                                                                                          \n",
    "    'Wan Dong score 2': ifs.score.wan_dong_score_2,                                                                                          \n",
    "    'Wei score': ifs.score.wei_score,                                                                                          \n",
    "    'Zhang Xu score 1': ifs.score.zhang_xu_score_1,                                                                                          \n",
    "    'Zhang Xu score 2': ifs.score.zhang_xu_score_2,                                                                                          \n",
    "}\n",
    "\n",
    "x = np.array([0.8, 0.15])\n",
    "\n",
    "for name, score in score_functions.items():\n",
    "    d = score(x)\n",
    "    print(f'{name}: {d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights\n",
    "\n",
    "Criteria weights in multi-criteria problems are responsible for the importance of each parameter taken into consideration. The greater value assigned to the given criterion, the more important it will be in the assessment. For the purpose of weights definition, different methods from the library can be used. They are based on the statistical approach, which makes it possible to define the weights objectively, relying only on data diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burillo Entropy \n",
      " [0.25 0.25 0.25 0.25]\n",
      "\n",
      "Equal \n",
      " [[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "\n",
      "Entropy \n",
      " [[-1.  1.  1.  0.]]\n",
      "\n",
      "Liu Entropy \n",
      " [0.865 0.884 0.738 0.746]\n",
      "\n",
      "Szmidt Entropy \n",
      " [0.715 0.675 0.425 0.411]\n",
      "\n",
      "Thakur Entropy \n",
      " [0.252 0.252 0.246 0.251]\n",
      "\n",
      "Ye Entropy \n",
      " [0.988 0.989 0.943 0.948]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights_methods = {\n",
    "    'Burillo Entropy': ifs_weights.burillo_entropy_weights,\n",
    "    'Equal': ifs_weights.equal_weights,\n",
    "    'Entropy': ifs_weights.entropy_weights,\n",
    "    'Liu Entropy': ifs_weights.liu_entropy_weights,\n",
    "    'Szmidt Entropy': ifs_weights.szmidt_entropy_weights,\n",
    "    'Thakur Entropy': ifs_weights.thakur_entropy_weights,\n",
    "    'Ye Entropy': ifs_weights.ye_entropy_weights,\n",
    "}\n",
    "\n",
    "for name, method in weights_methods.items():\n",
    "    w = method(matrix)\n",
    "    print(f'{name} \\n {w}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "\n",
    "Different techniques from the group of Fuzzy Multi-Criteria Decision Analysis methods based on the Intuitionistic Fuzzy Sets can be used to assess the alternatives. The library includes 9 methods which can be used for this purpose. The examples of their application are presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision matrix\n",
    "\n",
    "Decision matrix represents the alternatives taken into consideration in the problem. Rows represent amount of alternatives, when columns describes the amount of criteria in the given problem. In the case presented below, we have 5 alternatives and 4 criteria. Moreover, all elements in the matrix should be represent as the Intuitionistic Fuzzy Sets. Both representations with 2 or 3 elements in a fuzzy set are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([\n",
    "    [[0.4745, 0.5255], [0.4752, 0.5248], [0.2981, 0.7019], [0.4374, 0.5627]],\n",
    "    [[0.5346, 0.4654], [0.5532, 0.4468], [0.6300, 0.3700], [0.5901, 0.4099]],\n",
    "    [[0.4324, 0.5676], [0.4030, 0.5970], [0.4298, 0.5702], [0.4361, 0.5639]],\n",
    "    [[0.5235, 0.4765], [0.4808, 0.5192], [0.5667, 0.4333], [0.2913, 0.7087]],\n",
    "    [[0.4168, 0.5832], [0.4923, 0.5077], [0.4732, 0.5268], [0.4477, 0.5523]]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights\n",
    "\n",
    "Weights can be defined objectively, as shown above with the given examples. However, the weights can be also defined directly based on expert knowledge. The library is implemented in a way to handle both crisp and fuzzy weights. Amount of weights should equal the criteria amount. They can be determined as follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "Crisp weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisp_weights = np.array([0.2, 0.3, 0.15, 0.35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "Intuitionistic Fuzzy Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_weights = np.array([[0.6, 0.35], [0.8, 0.2], [0.5, 0.45], [0.2, 0.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria \n",
    "\n",
    "Criteria types are used to reflect the direction of the values that is preferable in the problem. If the values for given criterion should be as big as possible, it is then a profit type and represent as `1` in the criteria types array. If the values should be as low as possible, it is then cost and should be represent as `-1` in the array. Moreover, the criteria types amount should equal amount of criteria in the decision matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = np.array([1, -1, 1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF-ARAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_aras = methods.ifARAS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF-ARAS evaluation results with crisp and fuzzy weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crisp weights: [0.914 0.91  0.933 0.977 0.917]\n",
      "Fuzzy weights: [0.879 0.915 0.909 0.968 0.895]\n"
     ]
    }
   ],
   "source": [
    "print(f'Crisp weights: {if_aras(matrix, crisp_weights, types)}')\n",
    "print(f'Fuzzy weights: {if_aras(matrix, fuzzy_weights, types)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ARAS method can be used with different normalizations. Default, it is a `swap_normalization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aras = {\n",
    "    'Ecer normalization': methods.ifARAS(normalization=ifs.normalization.ecer_normalization),\n",
    "    'Minmax normalization': methods.ifARAS(normalization=ifs.normalization.minmax_normalization),\n",
    "    'Supriya normalization': methods.ifARAS(normalization=ifs.normalization.supriya_normalization),\n",
    "    'Swap normalization': methods.ifARAS(normalization=ifs.normalization.swap_normalization),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every normalization technique, the assessment can be performed to obtain results and check if the type of normalization impacts the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in aras.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                   A1    A2    A3    A4    A5\n",
      "---------------------  ----  ----  ----  ----  ----\n",
      "Ecer normalization     0.72  0.82  0.76  0.92  0.73\n",
      "Minmax normalization   0.47  0.67  0.59  0.75  0.46\n",
      "Supriya normalization  0.83  1.28  0.81  0.92  0.86\n",
      "Swap normalization     0.88  0.91  0.91  0.97  0.89\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that different preferences are obtained with different normalizations. To check if the alternatives are ranked at the same place despite used normalization method, we can use the method from the library called `rank` which calculates ascending or descending position order based on given array. Since the IF-ARAS method assess better alternatives with higher values, the order should be descending. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                   A1    A2    A3    A4    A5\n",
      "---------------------  ----  ----  ----  ----  ----\n",
      "Ecer normalization        5     2     3     1     4\n",
      "Minmax normalization      4     2     3     1     5\n",
      "Supriya normalization     4     1     5     2     3\n",
      "Swap normalization        5     2     3     1     4\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *rank(pref, descending=True)] for name, pref in results.items()], \n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen, that the ranking of alternatives is different for different normalization techniques. So the user should bear in mind that different methods can have impact the final result obtained within selected evaluation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF-CODAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.056  2.182 -1.171  0.348 -0.303]\n"
     ]
    }
   ],
   "source": [
    "if_codas = methods.ifCODAS()\n",
    "print(if_codas(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the CODAS method we can also use different normalizations, as it was in the ARAS method. In addition, we can use different distance metrics to calculate the alternatives preference. Default the `distance_1` is the `euclidean_distance` and `distance_2` is the `hamming_distance`. While calling the fuzzy CODAS object, the `tau` parameter can be given, which is set to `0.05` as default. It is treated as the threshold parameter while calculating the relative assessment matrix. CODAS also assessed better alternatives with higher preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "codas = {\n",
    "    'Pair 1': methods.ifCODAS(distance_1=ifs.distance.euclidean_distance, distance_2=ifs.distance.hamming_distance),\n",
    "    'Pair 2': methods.ifCODAS(distance_1=ifs.distance.normalized_euclidean_distance, distance_2=ifs.distance.normalized_hamming_distance),\n",
    "    'Pair 3': methods.ifCODAS(distance_1=ifs.distance.wang_xin_distance_1, distance_2=ifs.distance.wang_xin_distance_2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when the CODAS object with different pairs of distances is defined, the results can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in codas.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method       A1    A2     A3    A4    A5\n",
      "--------  -----  ----  -----  ----  ----\n",
      "Pair 1    -1.06  2.18  -1.17  0.35  -0.3\n",
      "Pair 2    -0.23  0.48  -0.23  0.08  -0.1\n",
      "Pair 3    -1.04  2.14  -1.16  0.37  -0.3\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen, that different distance metrics also have impact on the final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF-COPRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.091 0.728 0.365 1.    0.3  ]\n"
     ]
    }
   ],
   "source": [
    "if_copras = methods.ifCOPRAS()\n",
    "print(if_copras(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the COPRAS technique, the used score function can be modified. The `thakur_score` is set as default. Similarly to previous methods, better alternatives are assessed with higher preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "copras = {\n",
    "    'Chen score 1': methods.ifCOPRAS(score=ifs.score.chen_score_1),                                                                                          \n",
    "    'Chen score 2': methods.ifCOPRAS(score=ifs.score.chen_score_2),                                                                                          \n",
    "    'Kharal score 1': methods.ifCOPRAS(score=ifs.score.kharal_score_1),                                                                                          \n",
    "    'Kharal score 2': methods.ifCOPRAS(score=ifs.score.kharal_score_2),                                                                                          \n",
    "    'Liu Wang score': methods.ifCOPRAS(score=ifs.score.liu_wang_score),                                                                                          \n",
    "    'Supriya score': methods.ifCOPRAS(score=ifs.score.supriya_score),                                                                                          \n",
    "    'Thakur score': methods.ifCOPRAS(score=ifs.score.thakur_score),                                                                                          \n",
    "    'Wan Dong score 1': methods.ifCOPRAS(score=ifs.score.wan_dong_score_1),                                                                                          \n",
    "    'Wan Dong score 2': methods.ifCOPRAS(score=ifs.score.wan_dong_score_2),                                                                                          \n",
    "    'Wei score': methods.ifCOPRAS(score=ifs.score.wei_score),                                                                                          \n",
    "    'Zhang Xu score 1': methods.ifCOPRAS(score=ifs.score.zhang_xu_score_1),                                                                                          \n",
    "    'Zhang Xu score 2': methods.ifCOPRAS(score=ifs.score.zhang_xu_score_2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in copras.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method              A1    A2    A3    A4    A5\n",
      "----------------  ----  ----  ----  ----  ----\n",
      "Chen score 1      0.29  0.75  0.51  1     0.46\n",
      "Chen score 2      0.9   0.92  0.94  1     0.92\n",
      "Kharal score 1    0.8   0.9   0.88  1     0.84\n",
      "Kharal score 2    0.97  0.99  1     0.96  0.97\n",
      "Liu Wang score    0.91  0.94  0.96  1     0.92\n",
      "Supriya score     0.92  0.96  0.98  1     0.93\n",
      "Thakur score      0.09  0.73  0.36  1     0.3\n",
      "Wan Dong score 1  0.95  0.96  0.97  1     0.96\n",
      "Wan Dong score 2  0.9   0.92  0.94  1     0.92\n",
      "Wei score         0.85  0.86  0.91  1     0.87\n",
      "Zhang Xu score 1  0.89  0.93  0.93  1     0.91\n",
      "Zhang Xu score 2  0.92  0.97  0.97  1     0.94\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy EDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.276 0.259 0.523 0.995 0.322]\n"
     ]
    }
   ],
   "source": [
    "if_edas = methods.ifEDAS()\n",
    "print(if_edas(matrix, crisp_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of using the IF-EDAS method, the normalization function and score function can be changed. EDAS also evaluate better alternatives with higher preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "edas = {\n",
    "    'Ecer normalization': methods.ifEDAS(normalization=ifs.normalization.ecer_normalization),\n",
    "    'Minmax normalization': methods.ifEDAS(normalization=ifs.normalization.minmax_normalization),\n",
    "    'Supriya normalization': methods.ifEDAS(normalization=ifs.normalization.supriya_normalization),\n",
    "    'Swap normalization': methods.ifEDAS(normalization=ifs.normalization.swap_normalization),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After IF-EDAS object definition, we can calculate the results based on using different normalizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in edas.items():\n",
    "    results[name] = function(matrix, crisp_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                  A1    A2    A3    A4    A5\n",
      "--------------------  ----  ----  ----  ----  ----\n",
      "Normalization 1       0.05  0.5   0     0.04  0.12\n",
      "Normalization 2       0.28  0.26  0.52  1     0.32\n",
      "Normalization 3       0.41  0.48  0.92  1     0.91\n",
      "Minmax normalization  0.06  0     0.17  0.34  0.01\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be noticed that the results are highly similar while using different methods to calculate score and obtain crisp values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF-MABAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.106 -0.186 -0.084  0.226 -0.276]\n"
     ]
    }
   ],
   "source": [
    "if_mabac = methods.ifMABAC()\n",
    "print(if_mabac(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While using the IF-MABAC method, the normalization, distance, score function and adjust parameters can be modified. MABAC classify better alternatives with higher preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mabac = {\n",
    "    'Euclidean' : methods.ifMABAC(distance=ifs.distance.euclidean_distance),\n",
    "    'Grzegorzewski': methods.ifMABAC(distance=ifs.distance.grzegorzewski_distance),\n",
    "    'Hamming': methods.ifMABAC(distance=ifs.distance.hamming_distance),\n",
    "    'Luo distance': methods.ifMABAC(distance=ifs.distance.luo_distance),\n",
    "    'Normalized Euclidean': methods.ifMABAC(distance=ifs.distance.normalized_euclidean_distance),\n",
    "    'Normalized Hamming': methods.ifMABAC(distance=ifs.distance.normalized_hamming_distance),\n",
    "    'Wang Xin 1': methods.ifMABAC(distance=ifs.distance.wang_xin_distance_1),\n",
    "    'Wang Xin 2': methods.ifMABAC(distance=ifs.distance.wang_xin_distance_2),\n",
    "    'Yang Chiclana': methods.ifMABAC(distance=ifs.distance.yang_chiclana_distance),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in mabac.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                   A1     A2     A3    A4     A5\n",
      "--------------------  -----  -----  -----  ----  -----\n",
      "Euclidean              0.18  -0.99  -0     0.64  -0.65\n",
      "Grzegorzewski         -0.36  -0.35  -0.09  0.32  -0.17\n",
      "Hamming                0.01  -0.92  -0.06  0.61  -0.58\n",
      "Luo distance          -0.11  -0.19  -0.08  0.23  -0.28\n",
      "Normalized Euclidean   0.1   -0.54  -0     0.35  -0.35\n",
      "Normalized Hamming     0     -0.27  -0.02  0.18  -0.17\n",
      "Wang Xin 1            -0.36  -0.28  -0.1   0.29  -0.16\n",
      "Wang Xin 2            -0.36  -0.21  -0.11  0.26  -0.15\n",
      "Yang Chiclana         -0.37  -0.15  -0.1   0.23  -0.18\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again it can seen, that different distances measure used in the assessment have impact on the final result from the IF-MABAC method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF-MAIRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.113 0.13  0.087 0.041 0.126]\n"
     ]
    }
   ],
   "source": [
    "if_mairca = methods.ifMAIRCA()\n",
    "print(if_mairca(matrix, crisp_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF-MAIRCA method allows for adjusting the parameters responsible for the normalization and the distance measures. Default settings covers the `minmax_normalization` and the `normalized_euclidean_distance`. MAIRCA assigns higher preference values to better classified alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mairca = {\n",
    "    'Euclidean' : methods.ifMAIRCA(distance=ifs.distance.euclidean_distance),\n",
    "    'Grzegorzewski': methods.ifMAIRCA(distance=ifs.distance.grzegorzewski_distance),\n",
    "    'Hamming': methods.ifMAIRCA(distance=ifs.distance.hamming_distance),\n",
    "    'Luo distance': methods.ifMAIRCA(distance=ifs.distance.luo_distance),\n",
    "    'Normalized Euclidean': methods.ifMAIRCA(distance=ifs.distance.normalized_euclidean_distance),\n",
    "    'Normalized Hamming': methods.ifMAIRCA(distance=ifs.distance.normalized_hamming_distance),\n",
    "    'Wang Xin 1': methods.ifMAIRCA(distance=ifs.distance.wang_xin_distance_1),\n",
    "    'Wang Xin 2': methods.ifMAIRCA(distance=ifs.distance.wang_xin_distance_2),\n",
    "    'Yang Chiclana': methods.ifMAIRCA(distance=ifs.distance.yang_chiclana_distance),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in mairca.items():\n",
    "    results[name] = function(matrix, crisp_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                  A1    A2    A3    A4    A5\n",
      "--------------------  ----  ----  ----  ----  ----\n",
      "Euclidean             0.11  0.13  0.09  0.04  0.13\n",
      "Grzegorzewski         0.11  0.13  0.09  0.04  0.13\n",
      "Hamming               0.11  0.13  0.09  0.04  0.13\n",
      "Luo distance          0.11  0.13  0.09  0.04  0.13\n",
      "Normalized Euclidean  0.11  0.13  0.09  0.04  0.13\n",
      "Normalized Hamming    0.11  0.13  0.09  0.04  0.13\n",
      "Wang Xin 1            0.11  0.13  0.09  0.04  0.13\n",
      "Wang Xin 2            0.11  0.13  0.09  0.04  0.13\n",
      "Yang Chiclana         0.11  0.13  0.09  0.04  0.13\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen, that using different distances in this particular case did not cause any changes in the assessments, which shows high robustness of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF-MOORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.046  0.024  0.036  0.079 -0.025]\n"
     ]
    }
   ],
   "source": [
    "if_moora = methods.ifMOORA()\n",
    "print(if_moora(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF-MOORA assigns higher preferences to better alternatives. It allows for the modification of the score function, and the default method is set to `zhnag_xu_score_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "moora = {\n",
    "    'Chen score 1': methods.ifMOORA(score=ifs.score.chen_score_1),                                                                                          \n",
    "    'Chen score 2': methods.ifMOORA(score=ifs.score.chen_score_2),                                                                                          \n",
    "    'Kharal score 1': methods.ifMOORA(score=ifs.score.kharal_score_1),                                                                                          \n",
    "    'Kharal score 2': methods.ifMOORA(score=ifs.score.kharal_score_2),                                                                                          \n",
    "    'Liu Wang score': methods.ifMOORA(score=ifs.score.liu_wang_score),                                                                                          \n",
    "    'Supriya score': methods.ifMOORA(score=ifs.score.supriya_score),                                                                                          \n",
    "    'Thakur score': methods.ifMOORA(score=ifs.score.thakur_score),                                                                                          \n",
    "    'Wan Dong score 1': methods.ifMOORA(score=ifs.score.wan_dong_score_1),                                                                                          \n",
    "    'Wan Dong score 2': methods.ifMOORA(score=ifs.score.wan_dong_score_2),                                                                                          \n",
    "    'Wei score': methods.ifMOORA(score=ifs.score.wei_score),                                                                                          \n",
    "    'Zhang Xu score 1': methods.ifMOORA(score=ifs.score.zhang_xu_score_1),                                                                                          \n",
    "    'Zhang Xu score 2': methods.ifMOORA(score=ifs.score.zhang_xu_score_2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in moora.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method               A1     A2     A3     A4     A5\n",
      "----------------  -----  -----  -----  -----  -----\n",
      "Chen score 1      -0.08   0.06   0.08   0.2   -0.04\n",
      "Chen score 2      -0.04   0.03   0.04   0.1   -0.02\n",
      "Kharal score 1    -0.06   0.04   0.06   0.13  -0.03\n",
      "Kharal score 2    -0.01  -0.01  -0     -0.03  -0.01\n",
      "Liu Wang score    -0.04   0.03   0.04   0.1   -0.02\n",
      "Supriya score     -0.05   0.02   0.04   0.08  -0.02\n",
      "Thakur score      -0.08   0.06   0.08   0.19  -0.03\n",
      "Wan Dong score 1  -0.02   0.01   0.02   0.05  -0.01\n",
      "Wan Dong score 2  -0.04   0.03   0.04   0.1   -0.02\n",
      "Wei score         -0.03  -0.01   0.03   0.02  -0.01\n",
      "Zhang Xu score 1  -0.04   0.03   0.04   0.1   -0.02\n",
      "Zhang Xu score 2  -0.05   0.02   0.04   0.08  -0.02\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF-TOPSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.276 0.589 0.46  0.804 0.473]\n"
     ]
    }
   ],
   "source": [
    "if_topsis = methods.ifTOPSIS()\n",
    "print(if_topsis(matrix, crisp_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF-TOPSIS technique allows for adjusting the parameters responsible the distance calculation. Default distance is set to `normalized_euclidean_distance`. TOPSIS assures, that better alternatives have higher preferences values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "topsis = {\n",
    "    'Euclidean' : methods.ifTOPSIS(distance=ifs.distance.euclidean_distance),\n",
    "    'Grzegorzewski': methods.ifTOPSIS(distance=ifs.distance.grzegorzewski_distance),\n",
    "    'Hamming': methods.ifTOPSIS(distance=ifs.distance.hamming_distance),\n",
    "    'Luo distance': methods.ifTOPSIS(distance=ifs.distance.luo_distance),\n",
    "    'Normalized Hamming': methods.ifTOPSIS(distance=ifs.distance.normalized_hamming_distance),\n",
    "    'Normalized Euclidean': methods.ifTOPSIS(distance=ifs.distance.normalized_euclidean_distance),\n",
    "    'Wang Xin 1': methods.ifTOPSIS(distance=ifs.distance.wang_xin_distance_1),\n",
    "    'Wang Xin 2': methods.ifTOPSIS(distance=ifs.distance.wang_xin_distance_2),\n",
    "    'Yang Chiclana': methods.ifTOPSIS(distance=ifs.distance.yang_chiclana_distance),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in topsis.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                  A1    A2    A3    A4    A5\n",
      "--------------------  ----  ----  ----  ----  ----\n",
      "Euclidean             0.31  0.56  0.54  0.77  0.4\n",
      "Grzegorzewski         0.31  0.55  0.53  0.78  0.4\n",
      "Hamming               0.31  0.55  0.53  0.78  0.4\n",
      "Luo distance          0.31  0.55  0.53  0.77  0.4\n",
      "Normalized Hamming    0.31  0.55  0.53  0.78  0.4\n",
      "Normalized Euclidean  0.3   0.57  0.53  0.72  0.45\n",
      "Wang Xin 1            0.31  0.56  0.53  0.77  0.4\n",
      "Wang Xin 2            0.31  0.56  0.54  0.77  0.4\n",
      "Yang Chiclana         0.31  0.57  0.54  0.76  0.4\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF-VIKOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S: [2.414 0.    2.861 1.653 2.233]\n",
      "R: [0.5 0.  0.8 0.7 0.6]\n",
      "Q: [0.734 0.    1.    0.726 0.765]\n"
     ]
    }
   ],
   "source": [
    "if_vikor = methods.ifVIKOR()\n",
    "res = if_vikor(matrix, fuzzy_weights, types)\n",
    "print(f'S: {res[0]}')\n",
    "print(f'R: {res[1]}')\n",
    "print(f'Q: {res[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIKOR method is characterized by returning three assessment vectors (S, R, Q). The difference between them lays in the way how they are calculated in the final phase of the evaluation. The VIKOR method performance can be adjusted with the distance method, which by default is set to `hamming_distance`. Moreover, while creating the IF-VIKOR object, the `v` parameter can be given, which translates how the weight of the strategy will behave. It is set to `0.5` as default. VIKOR ranking can be calculated by sorting the preferences in the ascending order, so in the `rank` method, the parameter should be sey as `descending=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vikor = {\n",
    "    'Euclidean' : methods.ifVIKOR(distance=ifs.distance.euclidean_distance),\n",
    "    'Grzegorzewski': methods.ifVIKOR(distance=ifs.distance.grzegorzewski_distance),\n",
    "    'Hamming': methods.ifVIKOR(distance=ifs.distance.hamming_distance),\n",
    "    'Luo distance': methods.ifVIKOR(distance=ifs.distance.luo_distance),\n",
    "    'Normalized Euclidean': methods.ifVIKOR(distance=ifs.distance.normalized_euclidean_distance),\n",
    "    'Normalized Hamming': methods.ifVIKOR(distance=ifs.distance.normalized_hamming_distance),\n",
    "    'Wang Xin 1': methods.ifVIKOR(distance=ifs.distance.wang_xin_distance_1),\n",
    "    'Wang Xin 2': methods.ifVIKOR(distance=ifs.distance.wang_xin_distance_2),\n",
    "    'Yang Chiclana': methods.ifVIKOR(distance=ifs.distance.yang_chiclana_distance),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in vikor.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                  A1    A2    A3    A4    A5\n",
      "--------------------  ----  ----  ----  ----  ----\n",
      "Euclidean             2.41     0  2.86  1.65  2.23\n",
      "Grzegorzewski         2.41     0  2.86  1.65  2.23\n",
      "Hamming               2.41     0  2.86  1.65  2.23\n",
      "Luo distance          2.41     0  2.86  1.65  2.23\n",
      "Normalized Euclidean  2.41     0  2.86  1.65  2.23\n",
      "Normalized Hamming    2.41     0  2.86  1.65  2.23\n",
      "Wang Xin 1            2.41     0  2.86  1.65  2.23\n",
      "Wang Xin 2            2.41     0  2.86  1.65  2.23\n",
      "Yang Chiclana         2.41     0  2.86  1.65  2.23\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref[0], 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(matrix.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "Correlation coefficients are used to indicate the similarity between preferences and rankings. In the PyIFDM package, there are implemented four different methods. The example of their usage is presented below. The `pearson_coef` and `spearman_coef` are used to compare the preference values, while `weighted_spearman_coef` and `ws_rank_similarity_coef` can be used to compare rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "Preferences comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson: 0.4790813778576422\n",
      "Spearman: 0.4790813778576422\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.62, 0.90, 0.53, 0.87, 0.12])\n",
    "y = np.array([0.56, 0.34, 0.54, 0.82, 0.32])\n",
    "\n",
    "print(f'Pearson: {corrs.pearson_coef(x, y)}')\n",
    "print(f'Spearman: {corrs.spearman_coef(x, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "Rankings comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Spearman: 0.55\n",
      "WS rank similarity: 0.6380208333333334\n"
     ]
    }
   ],
   "source": [
    "x = np.array([5, 3, 1, 2, 4])\n",
    "y = np.array([4, 1, 2, 3, 5])\n",
    "\n",
    "print(f'Weighted Spearman: {corrs.weighted_spearman_coef(x, y)}')\n",
    "print(f'WS rank similarity: {corrs.ws_rank_similarity_coef(x, y)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
